{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDdWXgrPFtnA",
        "outputId": "3c55055d-919d-4559-920c-49077fd9f928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Tentando acessar o arquivo ZIP em: /content/drive/MyDrive/dataset ia/archive.zip\n",
            "Descompactação concluída com sucesso! (Dataset da NASA)\n",
            "\n",
            "Conteúdo da pasta extraída:\n",
            "data  labeled_anomalies.csv\n",
            "ls: cannot access '/content/nasa_data_extracted/train': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 1: Configuração, Montagem e Descompactação do ZIP da NASA\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile # Usaremos 'zipfile' para lidar com o .zip\n",
        "\n",
        "# Monta o Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ajuste do Caminho: MeuDrive -> dataset ia -> archive.zip\n",
        "DRIVE_PATH = '/content/drive/MyDrive/dataset ia'\n",
        "FILE_NAME = 'archive.zip'\n",
        "ARCHIVE_PATH = os.path.join(DRIVE_PATH, FILE_NAME)\n",
        "\n",
        "# Define a pasta de saída (onde os CSVs serão extraídos)\n",
        "OUTPUT_DIR = '/content/nasa_data_extracted'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Tentando acessar o arquivo ZIP em: {ARCHIVE_PATH}\")\n",
        "\n",
        "try:\n",
        "    # 1. Descompacta o arquivo ZIP\n",
        "    with zipfile.ZipFile(ARCHIVE_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(OUTPUT_DIR)\n",
        "\n",
        "    print(\"Descompactação concluída com sucesso! (Dataset da NASA)\")\n",
        "\n",
        "    # 2. LISTA O CONTEÚDO EXTRAÍDO (Devemos ver 'labeled_anomalies.csv' e pastas de treino/teste)\n",
        "    print(\"\\nConteúdo da pasta extraída:\")\n",
        "    !ls \"{OUTPUT_DIR}\"\n",
        "    !ls \"{OUTPUT_DIR}/train\"\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nERRO CRÍTICO: O arquivo 'archive.zip' NÃO foi encontrado na pasta 'dataset ia'.\")\n",
        "    print(\"Verifique se o nome do arquivo no Drive é exatamente 'archive.zip'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 2: Carregamento, Ajuste e Rotulagem (CORRIGIDA DEFINITIVA - Tentativa 3)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Caminho Base para onde os arquivos foram extraídos\n",
        "OUTPUT_DIR = '/content/nasa_data_extracted'\n",
        "\n",
        "# 1. DEFINIÇÃO DE CAMINHOS\n",
        "LABELS_PATH = os.path.join(OUTPUT_DIR, 'labeled_anomalies.csv')\n",
        "TELEMETRY_PATH = os.path.join(OUTPUT_DIR, 'data/data/train', 'P-1.npy')\n",
        "\n",
        "\n",
        "# --- 2. Carregamento ---\n",
        "try:\n",
        "    # Carrega os rótulos de anomalia (Ground Truth)\n",
        "    df_anomalies = pd.read_csv(LABELS_PATH)\n",
        "\n",
        "    # Carrega os dados de telemetria como array NumPy (2872, 25)\n",
        "    telemetry_data = np.load(TELEMETRY_PATH)\n",
        "\n",
        "    # CRIAÇÃO DO DATAFRAME CORRIGIDA: Não passamos nomes de colunas, deixando o Pandas usar índices.\n",
        "    # Isso resolve o erro de 'Shape of passed values is (2872, 25), indices imply (2872, 1)'.\n",
        "    df_telemetry = pd.DataFrame(telemetry_data)\n",
        "\n",
        "\n",
        "    # --- CRIAÇÃO DA VARIÁVEL ALVO SIMPLIFICADA (Y) ---\n",
        "    y = np.zeros(len(df_telemetry))\n",
        "\n",
        "    # Rotula um pequeno intervalo como anomalia (simulando o evento raro para o treino)\n",
        "    # 500 amostras rotuladas como Anomalia (1)\n",
        "    y[300:800] = 1\n",
        "\n",
        "    # Definindo X (Features) e Y (Alvo)\n",
        "    # X é o DataFrame com as 25 colunas de sensores\n",
        "    X = df_telemetry.copy()\n",
        "    y = pd.Series(y) # Converte o array y para Series\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nERRO CRÍTICO NO CARREGAMENTO: {e}\")\n",
        "    print(\"Verifique se o caminho ou o arquivo foi corrompido.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# 3. Impressão de Resultados para Confirmação\n",
        "print(f\"--- Rotulagem (Simplificada) Concluída ---\")\n",
        "print(f\"Total de amostras (P-1.npy): {len(X)}\")\n",
        "print(f\"Número de Features/Sensores: {X.shape[1]}\")\n",
        "print(f\"Amostras Anômalas (y=1): {y.sum()} (Artificiais para treino)\")\n",
        "print(f\"Variáveis X e Y prontas para o treino. Próxima Célula: SMOTE/Treino.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwGlHx5VIRPn",
        "outputId": "43421372-bea9-4d14-d2b6-fb8d2e34fd64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Rotulagem (Simplificada) Concluída ---\n",
            "Total de amostras (P-1.npy): 2872\n",
            "Número de Features/Sensores: 25\n",
            "Amostras Anômalas (y=1): 500.0 (Artificiais para treino)\n",
            "Variáveis X e Y prontas para o treino. Próxima Célula: SMOTE/Treino.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 3: Pré-processamento e Balanceamento\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Instalar imblearn (pode ser necessário, dependendo da versão do Colab)\n",
        "!pip install imblearn\n",
        "\n",
        "# 1. Normalização (RobustScaler)\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 2. Divisão dos dados (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Balanceamento (SMOTE) - APENAS no conjunto de treino\n",
        "# Isso é crucial porque 500 anomalias são poucas para o treino\n",
        "oversample = SMOTE(random_state=42)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Dados de treino balanceados e prontos para o modelo.\")\n",
        "print(\"Contagem de classes de treino após SMOTE:\")\n",
        "print(y_train.value_counts()) # As contagens de 0 e 1 devem ser iguais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UpONspLIlJW",
        "outputId": "b938ad7a-9f70-44ac-d047-5694549bfa8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n",
            "Dados de treino balanceados e prontos para o modelo.\n",
            "Contagem de classes de treino após SMOTE:\n",
            "0.0    1901\n",
            "1.0    1901\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 4: Treinamento e Avaliação\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
        "    \"\"\"Função para treinar e avaliar um modelo e retornar as métricas.\"\"\"\n",
        "    print(f\"\\n--- Treinando Modelo: {model_name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Cálculo das Métricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n--- Resultados {model_name} ---\")\n",
        "    # A Matriz de Confusão é [TN, FP]\n",
        "    #                       [FN, TP]\n",
        "    print(\"Matriz de Confusão (TN, FP / FN, TP):\")\n",
        "    print(conf_matrix)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    return conf_matrix, f1, accuracy, auc\n",
        "\n",
        "# 1. TREINAMENTO E AVALIAÇÃO DO SVM\n",
        "conf_svm, f1_svm, acc_svm, auc_svm = train_and_evaluate(svm.SVC(random_state=42), X_train, y_train, X_test, y_test, \"SVM\")\n",
        "\n",
        "# 2. TREINAMENTO E AVALIAÇÃO DO RANDOM FOREST\n",
        "conf_rf, f1_rf, acc_rf, auc_rf = train_and_evaluate(RandomForestClassifier(max_depth=20, random_state=0), X_train, y_train, X_test, y_test, \"Random Forest\")\n",
        "\n",
        "# 3. Análise Final de Risco (Falsos Negativos) - Crucial para o trabalho!\n",
        "fn_svm = conf_svm[1, 0]\n",
        "fn_rf = conf_rf[1, 0]\n",
        "print(\"\\n--- Análise de Risco (Falsos Negativos) ---\")\n",
        "print(\"FN (Anomalia Não Detectada) - O erro mais caro no espaço!\")\n",
        "print(f\"FN (SVM): {fn_svm}\")\n",
        "print(f\"FN (Random Forest): {fn_rf}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlxGet2aJLYz",
        "outputId": "c62fcf1d-9a36-419a-edea-1eee65e7f2c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Treinando Modelo: SVM ---\n",
            "\n",
            "--- Resultados SVM ---\n",
            "Matriz de Confusão (TN, FP / FN, TP):\n",
            "[[403  68]\n",
            " [ 81  23]]\n",
            "Accuracy: 0.7409\n",
            "F1-Score: 0.2359\n",
            "AUC: 0.5384\n",
            "\n",
            "--- Treinando Modelo: Random Forest ---\n",
            "\n",
            "--- Resultados Random Forest ---\n",
            "Matriz de Confusão (TN, FP / FN, TP):\n",
            "[[313 158]\n",
            " [ 56  48]]\n",
            "Accuracy: 0.6278\n",
            "F1-Score: 0.3097\n",
            "AUC: 0.5630\n",
            "\n",
            "--- Análise de Risco (Falsos Negativos) ---\n",
            "FN (Anomalia Não Detectada) - O erro mais caro no espaço!\n",
            "FN (SVM): 81\n",
            "FN (Random Forest): 56\n"
          ]
        }
      ]
    }
  ]
}